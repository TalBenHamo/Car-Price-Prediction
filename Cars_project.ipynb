{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87de2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7bf9892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Primary Heading\n",
       "This is a **bold** statement.\n",
       "\n",
       "## Subheading\n",
       "Here is a [link](https://www.example.com) to an example website.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "markdown_text = \"\"\"\n",
    "# Primary Heading\n",
    "This is a **bold** statement.\n",
    "\n",
    "## Subheading\n",
    "Here is a [link](https://www.example.com) to an example website.\n",
    "\"\"\"\n",
    "\n",
    "Markdown(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eee47a56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Data Acquisition\n",
       "We crawled each manufacturer separately and then combined all the data into one Excel file\n",
       "This code snippet crawl cars displays URLs from the Autotrader website, specifically targeting BMW cars. \n",
       "We used the BeautifulSoup library which is used to parse the HTML content of the page and create a BeautifulSoup object. \n",
       "The URLs are stored in the linksToPages list for further processing or analysis.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_text = \"\"\"\n",
    "# Data Acquisition\n",
    "This is the data acquisition process \n",
    "We crawled each manufacturer separately and then combined all the data into one Excel file\n",
    "This code snippet crawl cars displays URLs from the Autotrader website. \n",
    "We used the BeautifulSoup library which is used to parse the HTML content of the page and create a BeautifulSoup object. \n",
    "The URLs are stored in the linksToPages list for further processing or analysis.\n",
    "\"\"\"\n",
    "\n",
    "Markdown(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dd8dcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "\n",
       "#### BMW\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_text = \"\"\"\n",
    "\n",
    "\n",
    "#### BMW\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Markdown(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb72f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "linksToPages = []\n",
    "\n",
    "for i in range(0, 1000, 100):\n",
    "    if i==0:\n",
    "        url = \"https://www.autotrader.com/cars-for-sale/all-cars/Bmw/san-francisco-ca?searchRadius=75&zip=94102&marketExtension=include&isNewSearch=true&showAccelerateBanner=false&sortBy=relevance&numRecords=100\"\n",
    "      \n",
    "    else:\n",
    "        url = f\"https://www.autotrader.com/cars-for-sale/all-cars/Bmw/san-francisco-ca?searchRadius=75&zip=94102&marketExtension=include&isNewSearch=true&showAccelerateBanner=false&sortBy=relevance&numRecords=100&firstRecord={i}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    page_source = response.text\n",
    "\n",
    "    soup = bs(page_source, 'html.parser')\n",
    "    my_divs = soup.find_all('div', attrs={'class': \"inventory-listing cursor-pointer panel panel-default\"})\n",
    "\n",
    "    for div in my_divs:\n",
    "        for t in div.find_all('a'):\n",
    "            linksToPages.append(t['href'])\n",
    "            break\n",
    "    time.sleep(2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc49928b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "This code section retrieves specific data from each car listing page in the \n",
       "linksToPages list and stores it in a nested list called data.\n",
       "Finally, it saves the extracted data as an Excel file.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_text = \"\"\"\n",
    "This code section retrieves specific data from each car listing page in the \n",
    "linksToPages list and stores it in a nested list called data.\n",
    "Finally, it saves the extracted data as an Excel file.\n",
    "\"\"\"\n",
    "Markdown(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "linksToPages[:3]\n",
    "for link in linksToPages:\n",
    "    if link.startswith('/'):\n",
    "        url = 'https://www.autotrader.com' + link\n",
    "        res = requests.get(url)\n",
    "\n",
    "        soup = bs(res.content, 'html.parser')\n",
    "        items = soup.find('ul', attrs={'class': 'list'})\n",
    "        data_row = []\n",
    "\n",
    "        # Extract name if it is not None\n",
    "        name = soup.find('h1')\n",
    "        if name is not None:\n",
    "            data_row.append(name.text.strip())\n",
    "        else:\n",
    "            data_row.append('N/A')\n",
    "\n",
    "        # Extract price\n",
    "        price = soup.find('div', attrs={'data-cmp': 'pricing'})\n",
    "        if price is not None:\n",
    "            price_value = price.find('span', attrs={'class': 'first-price'})\n",
    "            if price_value is not None:\n",
    "                data_row.append(price_value.text.strip())\n",
    "            else:\n",
    "                data_row.append('N/A')\n",
    "        else:\n",
    "            data_row.append('N/A')\n",
    "\n",
    "        # Extract other details if items is not None\n",
    "        if items is not None:\n",
    "            for item in items.find_all(\"li\", attrs={'class': 'list-bordered'}):\n",
    "                data_row.append(item.text.strip())\n",
    "        else:\n",
    "            # Append 'N/A' values if no other details are found\n",
    "            for _ in range(6):\n",
    "                data_row.append('N/A')\n",
    "\n",
    "        data.append(data_row)\n",
    "\n",
    "\n",
    "\n",
    "# Save DataFrame as Excel file\n",
    "save_location = r\"C:\\Users\\tal66\\Desktop\\פרויקט טל ושקד מדעי הנתונים\\runs\\Bmw.xlsx\"\n",
    "df.to_excel(save_location, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ceaae3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "\n",
       "#### Chevrolet\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_text = \"\"\"\n",
    "\n",
    "\n",
    "#### Chevrolet\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Markdown(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb2a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linksToPages = []\n",
    "\n",
    "for i in range(0, 1000, 100):\n",
    "    if i==0:\n",
    "        url = \"https://www.autotrader.com/cars-for-sale/all-cars/chevrolet/san-francisco-ca?searchRadius=75&zip=94102&marketExtension=include&isNewSearch=true&showAccelerateBanner=false&sortBy=relevance&numRecords=100\"\n",
    "      \n",
    "    else:\n",
    "        url = f\"https://www.autotrader.com/cars-for-sale/all-cars/chevrolet/san-francisco-ca?searchRadius=75&zip=94102&marketExtension=include&isNewSearch=true&showAccelerateBanner=false&sortBy=relevance&numRecords=100&firstRecord={i}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    page_source = response.text\n",
    "\n",
    "    soup = bs(page_source, 'html.parser')\n",
    "    my_divs = soup.find_all('div', attrs={'class': \"inventory-listing cursor-pointer panel panel-default\"})\n",
    "\n",
    "    for div in my_divs:\n",
    "        for t in div.find_all('a'):\n",
    "            linksToPages.append(t['href'])\n",
    "            break\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea00150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = []\n",
    "for link in linksToPages:\n",
    "    if link.startswith('/'):\n",
    "        url = 'https://www.autotrader.com' + link\n",
    "        res = requests.get(url)\n",
    "        time.sleep(2)\n",
    "        soup = bs(res.content, 'html.parser')\n",
    "        items = soup.find('ul', attrs={'class': 'list'})\n",
    "        data_row = []\n",
    "\n",
    "        # Extract name if it is not None\n",
    "        name = soup.find('h1')\n",
    "        if name is not None:\n",
    "            data_row.append(name.text.strip())\n",
    "        else:\n",
    "            data_row.append('N/A')\n",
    "\n",
    "        # Extract price\n",
    "        price = soup.find('div', attrs={'data-cmp': 'pricing'})\n",
    "        if price is not None:\n",
    "            price_value = price.find('span', attrs={'class': 'first-price'})\n",
    "            if price_value is not None:\n",
    "                data_row.append(price_value.text.strip())\n",
    "            else:\n",
    "                data_row.append('N/A')\n",
    "        else:\n",
    "            data_row.append('N/A')\n",
    "\n",
    "        # Extract other details if items is not None\n",
    "        if items is not None:\n",
    "            for item in items.find_all(\"li\", attrs={'class': 'list-bordered'}):\n",
    "                data_row.append(item.text.strip())\n",
    "        else:\n",
    "            # Append 'N/A' values if no other details are found\n",
    "            for _ in range(6):\n",
    "                data_row.append('N/A')\n",
    "\n",
    "        data.append(data_row)\n",
    "\n",
    "\n",
    "\n",
    "# Save DataFrame as Excel file\n",
    "save_location = r\"C:\\Users\\tal66\\Desktop\\פרויקט טל ושקד מדעי הנתונים\\runs\\chevrolet.xlsx\"\n",
    "df.to_excel(save_location, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35bf280a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "\n",
       " This code section combines multiple Excel files located in a specified folder into a single DataFrame and saves the combined data as a new Excel file.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_text = \"\"\"\n",
    "\n",
    "\n",
    " This code section combines multiple Excel files located in a specified folder into a single DataFrame and saves the combined data as a new Excel file.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Markdown(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Folder path containing the Excel files\n",
    "folder_path = r\"C:\\Users\\tal66\\Desktop\\פרויקט טל ושקד מדעי הנתונים\\runs\"\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Iterate over files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".xlsx\") or filename.endswith(\".xls\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Read each Excel file into a DataFrame\n",
    "        df = pd.read_excel(file_path)\n",
    "        # Append the DataFrame to the combined_data\n",
    "        combined_data = combined_data.append(df, ignore_index=True)\n",
    "\n",
    "# Save the combined data to a new Excel file\n",
    "output_path = os.path.join(folder_path, \"combined_file.xlsx\")\n",
    "combined_data.to_excel(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcff33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3764511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
